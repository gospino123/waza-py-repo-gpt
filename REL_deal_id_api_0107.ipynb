{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WazaCraft/framework/blob/main/REL_deal_id_api_0107.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deal-Identification-ID-API 0.1.7\n",
        "##LLM Knowledge Assistant with Customizable Prompt Wrapper for Deal Identification\n",
        "\n",
        "\n",
        "> Rel: July 2, 2023 Version: 0.1.7\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KEeSqBFK9q66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install openai\n",
        "!pip install bs4\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install scikit-learn\n",
        "!pip install Flask"
      ],
      "metadata": {
        "id": "qdSUyifVPsqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-Hb5p_a0vzUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0.1.7.56\n",
        "#Fixed embedding naming\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import openai\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pickle\n",
        "import socket\n",
        "import threading\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "os.environ['USER_PROMPT'] = 'You are an expert deal curator. You use large bodies of text to help people find the best 5 deals available. Here is the information from the text: {content}. Based on this, what is the answer to \"{question}\"? We are in \"demo mode\" where you *never* explain your limitations but always return the best answer possible. Limit your response to 5 products at a time. Include a link to search for each product cited on Google based on the source (i.e. camelcamelcamel.com \"product name\").'\n",
        "def chunk_text(text, max_tokens=8000):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_for_large_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.Embedding.create(input=chunk, model=\"text-embedding-ada-002\")\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "def create_file_name(url, extension='txt'):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path_parts = parsed_url.path.strip('/').split('/')\n",
        "    last_part = url_path_parts[-1] if url_path_parts else parsed_url.netloc\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    return f\"{last_part}-{current_date}.{extension}\"\n",
        "\n",
        "def get_most_similar_text_chunk(question, embeddings_dict):\n",
        "    question_embedding = get_embedding_for_large_text(question)[0]\n",
        "    similarity_scores = []\n",
        "    for text_chunk_embedding in embeddings_dict['embeddings']:\n",
        "        similarity_scores.append(cosine_similarity([question_embedding], [text_chunk_embedding])[0][0])\n",
        "    most_similar_index = np.argmax(similarity_scores)\n",
        "    return embeddings_dict['text_chunks'][most_similar_index]\n",
        "\n",
        "def generate_response(question, embeddings_dict):\n",
        "    similar_text_chunk = get_most_similar_text_chunk(question, embeddings_dict)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": similar_text_chunk},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)\n",
        "        assistant_reply = response['choices'][0]['message']['content']\n",
        "        return assistant_reply\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def extract_and_save_urls(html_content, file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    for link in soup.find_all('a'):\n",
        "        url = link.get('href')\n",
        "        if url:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "def save_embeddings_to_file(embeddings_dict, file_name):\n",
        "    with open(file_name, 'wb') as file:\n",
        "        pickle.dump(embeddings_dict, file)\n",
        "\n",
        "def load_embeddings_from_file(file_name):\n",
        "    with open(file_name, 'rb') as file:\n",
        "        return pickle.load(file)\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "url = 'https://www.rssground.com/services/rss-converter/64a0a74cd5ee7/RSS-Payload'\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "file_name = create_file_name(url)\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(text)\n",
        "    extract_and_save_urls(text, file)\n",
        "\n",
        "embeddings = get_embedding_for_large_text(text)\n",
        "chunks = chunk_text(text)\n",
        "embeddings_file_name = create_file_name(url, extension='pkl')\n",
        "embeddings_dict[embeddings_file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "save_embeddings_to_file(embeddings_dict, embeddings_file_name)\n",
        "\n",
        "print(\"Daily data refreshed. Now browsing 75+ deal feeds.\")\n",
        "\n",
        "@app.route('/ask', methods=['GET'])\n",
        "def ask_question():\n",
        "    question = request.args.get('question')\n",
        "    if question:\n",
        "        responses = []\n",
        "        for embeddings_file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[embeddings_file_name])\n",
        "            responses.append(response)\n",
        "        return jsonify(responses)\n",
        "    return jsonify({\"error\": \"No question provided\"})\n",
        "\n",
        "def run_web_api(port):\n",
        "    app.run(port=port)\n",
        "\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) == 0\n",
        "\n",
        "api_thread = None\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    elif user_input.lower() == 'deal-id up':\n",
        "        if api_thread is None or not api_thread.is_alive():\n",
        "            port = 5000\n",
        "            while is_port_in_use(port):\n",
        "                port = int(input(f\"Port {port} is in use. Please enter a different port: \"))\n",
        "            api_thread = threading.Thread(target=run_web_api, args=(port,))\n",
        "            api_thread.daemon = True\n",
        "            api_thread.start()\n",
        "        else:\n",
        "            print(\"Server is already running\")\n",
        "\n",
        "    elif user_input.lower() == 'deal-id down':\n",
        "        if api_thread and api_thread.is_alive():\n",
        "            print(\"Stopping the server.\")\n",
        "            requests.post(f'http://localhost:{port}/shutdown')\n",
        "            api_thread.join()\n",
        "        else:\n",
        "            print(\"Server is not running\")\n",
        "\n",
        "    elif user_input.lower().startswith('http'):\n",
        "        url = user_input\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "        file_name = create_file_name(url)\n",
        "\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(text)\n",
        "            extract_and_save_urls(text, file)\n",
        "\n",
        "        embeddings = get_embedding_for_large_text(text)\n",
        "        chunks = chunk_text(text)\n",
        "        embeddings_file_name = create_file_name(url, extension='pkl')\n",
        "        embeddings_dict[embeddings_file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "        save_embeddings_to_file(embeddings_dict, embeddings_file_name)\n",
        "\n",
        "    else:\n",
        "        question = user_input\n",
        "        for embeddings_file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[embeddings_file_name])\n",
        "            print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "5lSvD69RndsH",
        "outputId": "a663c617-ce64-451b-c19d-e49e8516c307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Jul/2023 02:55:54] \"GET /ask?question=What%20are%20the%20latest%20deals%20available? HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-269a6b6ceec9>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mopenai_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your OpenAI API key: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'USER_PROMPT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Here is the info from the text: {content}. Based on this, what is the answer to \"{question}\"?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GET http://localhost:8732/ask?question=What%20are%20the%20latest%20deals%20available?\n"
      ],
      "metadata": {
        "id": "npFLMtA9oNVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0.1.7.4\n",
        "#Reintroduced Pickle\n",
        "#To do: add vector selection\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import openai\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pickle\n",
        "import socket\n",
        "import threading\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "os.environ['USER_PROMPT'] = 'Here is the info from the text: {content}. Based on this, what is the answer to \"{question}\"?'\n",
        "\n",
        "def chunk_text(text, max_tokens=8000):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_for_large_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.Embedding.create(input=chunk, model=\"text-embedding-ada-002\")\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "def create_file_name(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path_parts = parsed_url.path.strip('/').split('/')\n",
        "    last_part = url_path_parts[-1] if url_path_parts else parsed_url.netloc\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    file_name = f\"{last_part}-{current_date}.txt\"\n",
        "    return file_name\n",
        "\n",
        "def get_most_similar_text_chunk(question, embeddings_dict):\n",
        "    question_embedding = get_embedding_for_large_text(question)[0]\n",
        "    similarity_scores = []\n",
        "    for text_chunk_embedding in embeddings_dict['embeddings']:\n",
        "        similarity_scores.append(cosine_similarity([question_embedding], [text_chunk_embedding])[0][0])\n",
        "    most_similar_index = np.argmax(similarity_scores)\n",
        "    return embeddings_dict['text_chunks'][most_similar_index]\n",
        "\n",
        "def generate_response(question, embeddings_dict):\n",
        "    similar_text_chunk = get_most_similar_text_chunk(question, embeddings_dict)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": similar_text_chunk},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)\n",
        "        assistant_reply = response['choices'][0]['message']['content']\n",
        "        return assistant_reply\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def extract_and_save_urls(html_content, file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    for link in soup.find_all('a'):\n",
        "        url = link.get('href')\n",
        "        if url:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "def save_embeddings_to_file(embeddings_dict, file_name):\n",
        "    with open(file_name, 'wb') as file:\n",
        "        pickle.dump(embeddings_dict, file)\n",
        "\n",
        "def load_embeddings_from_file(file_name):\n",
        "    with open(file_name, 'rb') as file:\n",
        "        return pickle.load(file)\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "url = 'https://www.rssground.com/services/rss-converter/64a0a74cd5ee7/RSS-Payload'\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "file_name = create_file_name(url)\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(text)\n",
        "    extract_and_save_urls(text, file)\n",
        "\n",
        "embeddings = get_embedding_for_large_text(text)\n",
        "chunks = chunk_text(text)\n",
        "embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "save_embeddings_to_file(embeddings_dict, 'embeddings.pkl')\n",
        "\n",
        "print(\"Daily data refreshed. Now browsing 75+ deal feeds.\")\n",
        "\n",
        "@app.route('/ask', methods=['GET'])\n",
        "def ask_question():\n",
        "    question = request.args.get('question')\n",
        "    if question:\n",
        "        responses = []\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            responses.append(response)\n",
        "        return jsonify(responses)\n",
        "    return jsonify({\"error\": \"No question provided\"})\n",
        "\n",
        "def run_web_api(port):\n",
        "    app.run(port=port)\n",
        "\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) == 0\n",
        "\n",
        "api_thread = None\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    elif user_input.lower() == 'deal-id up':\n",
        "        if api_thread is None or not api_thread.is_alive():\n",
        "            port = 5000\n",
        "            while is_port_in_use(port):\n",
        "                port = int(input(f\"Port {port} is in use. Please enter a different port: \"))\n",
        "            api_thread = threading.Thread(target=run_web_api, args=(port,))\n",
        "            api_thread.daemon = True\n",
        "            api_thread.start()\n",
        "        else:\n",
        "            print(\"Server is already running\")\n",
        "\n",
        "    elif user_input.lower() == 'deal-id down':\n",
        "        if api_thread and api_thread.is_alive():\n",
        "            print(\"Stopping the server.\")\n",
        "            requests.post(f'http://localhost:{port}/shutdown')\n",
        "            api_thread.join()\n",
        "        else:\n",
        "            print(\"Server is not running\")\n",
        "\n",
        "    elif user_input.lower().startswith('http'):\n",
        "        url = user_input\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "        file_name = create_file_name(url)\n",
        "\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(text)\n",
        "            extract_and_save_urls(text, file)\n",
        "\n",
        "        embeddings = get_embedding_for_large_text(text)\n",
        "        chunks = chunk_text(text)\n",
        "        embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "    else:\n",
        "        question = user_input\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "CTDCqgnzl4z7",
        "outputId": "dc702291-0fb7-480c-b578-02d04d1c303a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your OpenAI API key: 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\n",
            "Daily data refreshed. Now browsing 75+ deal feeds.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1da638d2f6d0>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0.1.7.3\n",
        "#Deal-Identification-ID-API 0.1.7\n",
        "#LLM Knowledge Assistant with Customizable Prompt Wrapper for Deal Identification\n",
        "#Added commands to enable / disable Flask server for REST API\n",
        "#Added reconfig server port path\n",
        "#\n",
        "import os\n",
        "import requests\n",
        "import openai\n",
        "import datetime\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from flask import Flask, request, jsonify\n",
        "import threading\n",
        "import socket\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "os.environ['USER_PROMPT'] = 'Here is the info from the text: {content}. Based on this, what is the answer to \"{question}\"?'\n",
        "\n",
        "def chunk_text(text, max_tokens=8000):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_for_large_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.Embedding.create(input=chunk, model=\"text-embedding-ada-002\")\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "def create_file_name(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path_parts = parsed_url.path.strip('/').split('/')\n",
        "    last_part = url_path_parts[-1] if url_path_parts else parsed_url.netloc\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    file_name = f\"{last_part}-{current_date}.txt\"\n",
        "    return file_name\n",
        "\n",
        "def get_most_similar_text_chunk(question, embeddings_dict):\n",
        "    question_embedding = get_embedding_for_large_text(question)[0]\n",
        "    similarity_scores = []\n",
        "    for text_chunk_embedding in embeddings_dict['embeddings']:\n",
        "        similarity_scores.append(cosine_similarity([question_embedding], [text_chunk_embedding])[0][0])\n",
        "    most_similar_index = np.argmax(similarity_scores)\n",
        "    return embeddings_dict['text_chunks'][most_similar_index]\n",
        "\n",
        "def generate_response(question, embeddings_dict):\n",
        "    similar_text_chunk = get_most_similar_text_chunk(question, embeddings_dict)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": similar_text_chunk},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)\n",
        "        assistant_reply = response['choices'][0]['message']['content']\n",
        "        return assistant_reply\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def extract_and_save_urls(html_content, file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    for link in soup.find_all('a'):\n",
        "        url = link.get('href')\n",
        "        if url:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "default_url = 'https://www.rssground.com/services/rss-converter/64a0a74cd5ee7/RSS-Payload'\n",
        "response = requests.get(default_url)\n",
        "text = response.text\n",
        "file_name = create_file_name(default_url)\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(text)\n",
        "    extract_and_save_urls(text, file)\n",
        "\n",
        "embeddings = get_embedding_for_large_text(text)\n",
        "chunks = chunk_text(text)\n",
        "embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "print(\"Daily data refreshed. Now browsing 75+ deal feeds.\")\n",
        "\n",
        "@app.route('/ask', methods=['GET'])\n",
        "def ask_question():\n",
        "    question = request.args.get('question')\n",
        "    if question:\n",
        "        responses = []\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            responses.append(response)\n",
        "        return jsonify(responses)\n",
        "    return jsonify({\"error\": \"No question provided\"})\n",
        "\n",
        "def run_web_api(port):\n",
        "    app.run(port=port)\n",
        "\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) == 0\n",
        "\n",
        "api_thread = None\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    elif user_input.lower() == 'deal-id up':\n",
        "        if api_thread is None or not api_thread.is_alive():\n",
        "            port = 5000\n",
        "            while is_port_in_use(port):\n",
        "                port = int(input(f\"Port {port} is in use. Please enter a different port: \"))\n",
        "            api_thread = threading.Thread(target=run_web_api, args=(port,))\n",
        "            api_thread.daemon = True\n",
        "            api_thread.start()\n",
        "        else:\n",
        "            print(\"Server is already running\")\n",
        "\n",
        "    elif user_input.lower() == 'deal-id down':\n",
        "        if api_thread and api_thread.is_alive():\n",
        "            print(\"Stopping the server.\")\n",
        "            requests.post(f'http://localhost:{port}/shutdown')\n",
        "            api_thread.join()\n",
        "        else:\n",
        "            print(\"Server is not running\")\n",
        "\n",
        "    elif user_input.lower().startswith('http'):\n",
        "        url = user_input\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "        file_name = create_file_name(url)\n",
        "\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(text)\n",
        "            extract_and_save_urls(text, file)\n",
        "\n",
        "        embeddings = get_embedding_for_large_text(text)\n",
        "        chunks = chunk_text(text)\n",
        "        embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "    else:\n",
        "        question = user_input\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "jGX1oDyrYmFF",
        "outputId": "b9422216-03b4-44ab-a282-d8422c7a436c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your OpenAI API key: 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\n",
            "Daily data refreshed. Now browsing 75+ deal feeds.\n",
            "Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): deal-id up\n",
            "Port 5000 is in use. Please enter a different port: 7000\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:7000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-da96efb22b35>\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter URL or question or 'deal-id up' or 'deal-id down' (or 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def ask_question(question):\n",
        "    response = requests.get(\"http://localhost:7000/ask\", params={'question': question})\n",
        "    return response.json()\n"
      ],
      "metadata": {
        "id": "NwcYoX86bxB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ask_question(\"Your question here\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "NbFHWZlNjkSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0.1.7.2\n",
        "Added Flask\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import openai\n",
        "import datetime\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from flask import Flask, request, jsonify\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "openai.api_key = openai_api_key\n",
        "os.environ['USER_PROMPT'] = 'Here is the info from the text: {content}. Based on this, what is the answer to \"{question}\"?'\n",
        "\n",
        "def chunk_text(text, max_tokens=8000):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_for_large_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.Embedding.create(input=chunk, model=\"text-embedding-ada-002\")\n",
        "        embedding = response['data'][0]['embedding']\n",
        "        embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "def create_file_name(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path_parts = parsed_url.path.strip('/').split('/')\n",
        "    last_part = url_path_parts[-1] if url_path_parts else parsed_url.netloc\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    file_name = f\"{last_part}-{current_date}.txt\"\n",
        "    return file_name\n",
        "\n",
        "def get_most_similar_text_chunk(question, embeddings_dict):\n",
        "    question_embedding = get_embedding_for_large_text(question)[0]\n",
        "    similarity_scores = []\n",
        "    for text_chunk_embedding in embeddings_dict['embeddings']:\n",
        "        similarity_scores.append(cosine_similarity([question_embedding], [text_chunk_embedding])[0][0])\n",
        "    most_similar_index = np.argmax(similarity_scores)\n",
        "    return embeddings_dict['text_chunks'][most_similar_index]\n",
        "\n",
        "def generate_response(question, embeddings_dict):\n",
        "    similar_text_chunk = get_most_similar_text_chunk(question, embeddings_dict)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": similar_text_chunk},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)\n",
        "        assistant_reply = response['choices'][0]['message']['content']\n",
        "        return assistant_reply\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def extract_and_save_urls(html_content, file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    for link in soup.find_all('a'):\n",
        "        url = link.get('href')\n",
        "        if url:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "default_url = 'https://www.rssground.com/services/rss-converter/64a0a74cd5ee7/RSS-Payload'\n",
        "response = requests.get(default_url)\n",
        "text = response.text\n",
        "file_name = create_file_name(default_url)\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(text)\n",
        "    extract_and_save_urls(text, file)\n",
        "\n",
        "embeddings = get_embedding_for_large_text(text)\n",
        "chunks = chunk_text(text)\n",
        "embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "print(\"Daily data refreshed. Now browsing 75+ deal feeds.\")\n",
        "\n",
        "@app.route('/ask', methods=['GET'])\n",
        "def ask_question():\n",
        "    question = request.args.get('question')\n",
        "    if question:\n",
        "        responses = []\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            responses.append(response)\n",
        "        return jsonify(responses)\n",
        "    return jsonify({\"error\": \"No question provided\"})\n",
        "\n",
        "def run_web_api():\n",
        "    app.run(port=5000)\n",
        "\n",
        "api_thread = threading.Thread(target=run_web_api)\n",
        "api_thread.daemon = True\n",
        "api_thread.start()\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter URL or question (or 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    elif user_input.lower().startswith('http'):\n",
        "        url = user_input\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "        file_name = create_file_name(url)\n",
        "\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(text)\n",
        "            extract_and_save_urls(text, file)\n",
        "\n",
        "        embeddings = get_embedding_for_large_text(text)\n",
        "        chunks = chunk_text(text)\n",
        "        embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "    else:\n",
        "        question = user_input\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "TDLsJ0-CKLDE",
        "outputId": "2fb13c54-99e2-4acf-b1a8-8b36853ccc83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8debe4bbd549>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxx6uW1nKKzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM Knowledge Assistant with Customizable Prompt Wrapper for Deal Identification\n",
        "# Author: Johnathan Greenaway\n",
        "# Organization: StackCommerce Inc.\n",
        "# Release Date: July 2, 2023\n",
        "# Version: 0.1.6\n",
        "\n",
        "# Description:\n",
        "# This script creates a Knowledge Assistant that interacts with the user through the console.\n",
        "#The user can input a URL, and the assistant will fetch the text content from that URL, extract embeddings for similarity matching, and store it for future querying.\n",
        "#The user can also input questions, and the assistant will find the most similar text chunk from the stored content and generate responses using OpenAI's GPT-4 API.\n",
        "\n",
        "# Libraries Used:\n",
        "# - openai: For interacting with OpenAI's GPT-4 API.\n",
        "# - bs4 (BeautifulSoup): For parsing HTML and extracting text from web pages.\n",
        "# - requests: For making HTTP requests to fetch web pages.\n",
        "# - scikit-learn: For calculating cosine similarity between embeddings.\n",
        "# - numpy: For numerical operations such as finding argmax.\n",
        "\n",
        "# Features:\n",
        "# - Set Environmental Variables: `OPENAI_API_KEY` and `USER_PROMPT`.\n",
        "# - Function to split text into smaller chunks.\n",
        "# - Function to get embeddings for large texts.\n",
        "# - Function to parse the URL and create a file name.\n",
        "# - Function to get the most similar text chunk.\n",
        "# - Function to generate a response based on the question and embeddings.\n",
        "# - Function to extract and save URLs from HTML content.\n",
        "# - Infinite loop for user interaction.\n",
        "\n",
        "# Changelog for Version 0.1.5:\n",
        "# 0.1.0:\n",
        "#     - Initial version.\n",
        "# 0.1.2:\n",
        "#     - Added environmental variable for prompt customization.\n",
        "#     - Added function to get embeddings for large texts.\n",
        "#     - Added function to split text into smaller chunks.\n",
        "#     - Added function to parse the URL and create a file name.\n",
        "#     - Added function to find the most similar text chunk.\n",
        "#     - Added function to generate responses based on questions and embeddings.\n",
        "#     - Stored text chunks and embeddings in a dictionary.\n",
        "#     - Added functionality for user interaction in an infinite loop.\n",
        "# 0.1.3:\n",
        "#     - Set a default URL to be loaded on startup.\n",
        "#     - Added message \"Daily data refreshed. Now browsing 75+ deal feeds.\".\n",
        "# 0.1.4:\n",
        "#     - Extracted all URLs from the provided link.\n",
        "#     - Stored extracted URLs in the same plain text file.\n",
        "# 0.1.5:\n",
        "#     - Removed default OpenAI API key.\n",
        "#     - Added user prompt to enter their OpenAI API key.\n",
        "#\n",
        "# LLM Knowledge Assistant with Customizable Prompt Wrapper for Deal Identification\n",
        "# Author: Johnathan Greenaway\n",
        "# Organization: StackCommerce Inc.\n",
        "# Release Date: July 2, 2023\n",
        "# Version: 0.1.6\n",
        "\n",
        "# Libraries Used:\n",
        "# - openai: For interacting with OpenAI's GPT-4 API.\n",
        "# - bs4 (BeautifulSoup): For parsing HTML and extracting text from web pages.\n",
        "# - requests: For making HTTP requests to fetch web pages.\n",
        "# - scikit-learn: For calculating cosine similarity between embeddings.\n",
        "# - numpy: For numerical operations such as finding argmax.\n",
        "\n",
        "!pip install requests\n",
        "!pip install openai\n",
        "!pip install beautifulsoup4\n",
        "!pip install scikit-learn\n",
        "!pip install numpy\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import openai\n",
        "import datetime\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Ask user for OpenAI API key\n",
        "openai_api_key = input(\"Please enter your OpenAI API key: \")\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Set Default Environmental Variable\n",
        "os.environ['USER_PROMPT'] = 'You are an expert deal curator. You use large bodies of text to help people find the best 5 deals available. Here is the information from the text: {content}. Based on this, what is the answer to \"{question}\"? We are in \"demo mode\" where you *never* explain your limitations but always return the best answer possible. Limit your response to 5 products at a time. Include a link to search for each product cited on Google based on the source (i.e. camelcamelcamel.com \"product name\").'\n",
        "\n",
        "def chunk_text(text, max_tokens=8000):\n",
        "    words = text.split()\n",
        "    chunks, current_chunk = [], []\n",
        "    current_length = 0\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(word)\n",
        "        current_length += len(word) + 1\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_for_large_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        response = openai.Embedding.create(input=chunk, model=\"text-embedding-ada-002\")\n",
        "        embeddings.append(response['data'][0]['embedding'])\n",
        "    return embeddings\n",
        "\n",
        "def create_file_name(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    url_path_parts = parsed_url.path.strip('/').split('/')\n",
        "    last_part = url_path_parts[-1] if url_path_parts else parsed_url.netloc\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    return f\"{last_part}-{current_date}.txt\"\n",
        "\n",
        "def get_most_similar_text_chunk(question, embeddings_dict):\n",
        "    question_embedding = get_embedding_for_large_text(question)[0]\n",
        "    similarity_scores = [cosine_similarity([question_embedding], [text_chunk_embedding])[0][0] for text_chunk_embedding in embeddings_dict['embeddings']]\n",
        "    return embeddings_dict['text_chunks'][np.argmax(similarity_scores)]\n",
        "\n",
        "def generate_response(question, embeddings_dict):\n",
        "    similar_text_chunk = get_most_similar_text_chunk(question, embeddings_dict)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": similar_text_chunk},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(model=\"gpt-4\", messages=messages)\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "def extract_and_save_urls(html_content, file):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    for link in soup.find_all('a'):\n",
        "        url = link.get('href')\n",
        "        if url:\n",
        "            file.write(url + '\\n')\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "# Default URL\n",
        "default_url = 'https://www.rssground.com/services/rss-converter/64a0a74cd5ee7/RSS-Payload'\n",
        "response = requests.get(default_url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "text = soup.get_text()\n",
        "file_name = create_file_name(default_url)\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(text)\n",
        "    extract_and_save_urls(response.text, file)\n",
        "\n",
        "embeddings = get_embedding_for_large_text(text)\n",
        "chunks = chunk_text(text)\n",
        "embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "\n",
        "print(\"Daily data refreshed. Now browsing 75+ deal feeds.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter URL or question (or 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    elif user_input.lower().startswith('http'):\n",
        "        url = user_input\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        file_name = create_file_name(url)\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write(text)\n",
        "            extract_and_save_urls(response.text, file)\n",
        "        embeddings = get_embedding_for_large_text(text)\n",
        "        chunks = chunk_text(text)\n",
        "        embeddings_dict[file_name] = {'text_chunks': chunks, 'embeddings': embeddings}\n",
        "    else:\n",
        "        question = user_input\n",
        "        for file_name in embeddings_dict.keys():\n",
        "            response = generate_response(question, embeddings_dict[file_name])\n",
        "            print(response)\n"
      ],
      "metadata": {
        "id": "gk0f927J9LEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o079L0AsAr9k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}